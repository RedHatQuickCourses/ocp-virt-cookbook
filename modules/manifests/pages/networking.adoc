= Networking Manifests
:navtitle: Networking

== Overview

This page provides Network Attachment Definition (NAD) manifests and network configuration examples for OpenShift Virtualization, organized by network topology type.

== Network Topology Types

OpenShift Virtualization supports several network topologies:

* **Localnet**: Direct access to physical network via OVS bridge
* **Layer2 UDN**: User Defined Networks with Layer 2 connectivity
* **Overlay**: OVN overlay networks (cloud-like networking)
* **Linux Bridges**: Traditional Linux bridge networking
* **Bond Interfaces**: Network interface bonding for redundancy

== Localnet Networks

Localnet topology provides VMs with direct access to physical network infrastructure through the OVS (Open vSwitch) bridge.

=== Localnet with VLAN Tagging

xref:attachment$networking/localnet-vlan-100-nad.yaml[Download localnet-vlan-100-nad.yaml]

[source,yaml]
----
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: localnet-vlan-100
  namespace: default
spec:
  config: |
    {
      "cniVersion": "0.3.1",
      "name": "localnet-vlan-100",
      "type": "ovn-k8s-cni-overlay",
      "topology": "localnet",
      "netAttachDefName": "default/localnet-vlan-100",
      "vlanID": 100,
      "subnets": "192.168.100.0/24",
      "excludeSubnets": "192.168.100.1/32"
    }
----

**Purpose:** Connects VMs to physical VLAN 100.

**Key Fields:**

* `topology: localnet` - Direct physical network access
* `vlanID: 100` - VLAN tag (must match physical switch configuration)
* `subnets` - IP range for the network
* `excludeSubnets` - IPs to exclude (typically gateway)

**Prerequisites:**

* OVS bridge configured with physnet mapping
* Physical switch port configured for VLAN trunking
* xref:networking:ovs-bridge-troubleshooting.adoc[]

=== Localnet without VLAN (Native)

xref:attachment$networking/localnet-native-nad.yaml[Download localnet-native-nad.yaml]

[source,yaml]
----
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: localnet-native
  namespace: default
spec:
  config: |
    {
      "cniVersion": "0.3.1",
      "name": "localnet-native",
      "type": "ovn-k8s-cni-overlay",
      "topology": "localnet",
      "netAttachDefName": "default/localnet-native",
      "subnets": "192.168.1.0/24",
      "excludeSubnets": "192.168.1.1/32"
    }
----

**When to use:** When VMs need access to untagged (native) VLAN on physical network.

**Note:** No `vlanID` field means native/untagged VLAN.

=== Localnet with Static IPAM

xref:attachment$networking/localnet-static-ipam-nad.yaml[Download localnet-static-ipam-nad.yaml]

[source,yaml]
----
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: localnet-static-ipam
  namespace: default
spec:
  config: |
    {
      "cniVersion": "0.3.1",
      "name": "localnet-static",
      "type": "ovn-k8s-cni-overlay",
      "topology": "localnet",
      "netAttachDefName": "default/localnet-static-ipam",
      "subnets": "192.168.100.0/24",
      "excludeSubnets": "192.168.100.1-192.168.100.50",
      "ipam": {
        "type": "static"
      }
    }
----

**When to use:** When VMs use cloud-init for static IP configuration rather than OVN-Kubernetes IPAM.

**Note:** Use with cloud-init `networkData` to configure static IPs.

=== Related Tutorials

* xref:networking:localnet-secondary.adoc[]
* xref:networking:localnet-vlan.adoc[]
* xref:networking:ovs-bridge-troubleshooting.adoc[]

== User Defined Networks (UDN)

UDNs allow creating custom primary networks for VMs, providing Layer 2 connectivity with isolated broadcast domains.

=== Layer 2 UDN

xref:attachment$networking/layer2-udn.yaml[Download layer2-udn.yaml]

[source,yaml]
----
apiVersion: k8s.ovn.org/v1
kind: UserDefinedNetwork
metadata:
  name: vm-layer2-network
  namespace: vm-guests
spec:
  topology: Layer2
  layer2:
    role: Primary
    subnets:
      - "192.168.100.0/24"
    mtu: 1400
    ipamLifecycle: Persistent
----

**Purpose:** Creates a Layer 2 network for VM primary network attachment.

**Key Fields:**

* `topology: Layer2` - Layer 2 broadcast domain
* `role: Primary` - Can be used as VM primary network
* `subnets` - IP range for the network
* `ipamLifecycle: Persistent` - IPs persist across VM reboots

=== Layer 2 NAD for UDN

After creating the UDN, create a NAD to reference it:

xref:attachment$networking/layer2-nad-for-udn.yaml[Download layer2-nad-for-udn.yaml]

[source,yaml]
----
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: vm-layer2-nad
  namespace: vm-guests
spec:
  config: |
    {
      "cniVersion": "0.3.1",
      "name": "vm-layer2-network",
      "type": "ovn-k8s-cni-overlay",
      "topology": "layer2",
      "role": "primary",
      "netAttachDefName": "vm-guests/vm-layer2-nad",
      "subnets": "192.168.100.0/24",
      "allowPersistentIPs": true,
      "layer2": {
        "subnets": ["192.168.100.0/24"],
        "joinSubnets": ["192.168.100.0/24"],
        "mtu": 1400
      }
    }
----

**When to use:** When VMs need custom primary network separate from pod network.

=== Related Tutorials

* xref:networking:udn-primary-networks.adoc[]

== Linux Bridges

Linux bridges provide traditional bridge networking for VMs on a per-node basis.

=== Linux Bridge Node Configuration

Use NMState to configure Linux bridge on nodes:

xref:attachment$networking/linux-bridge-nncp.yaml[Download linux-bridge-nncp.yaml]

[source,yaml]
----
apiVersion: nmstate.io/v1
kind: NodeNetworkConfigurationPolicy
metadata:
  name: br-vlan100-policy
spec:
  nodeSelector:
    node-role.kubernetes.io/worker: ""
  desiredState:
    interfaces:
      - name: br-vlan100
        description: Linux bridge for VLAN 100
        type: linux-bridge
        state: up
        ipv4:
          enabled: false
        bridge:
          options:
            stp:
              enabled: false
          port:
            - name: ens224
              vlan:
                mode: access
                tag: 100
----

**Purpose:** Creates Linux bridge attached to physical interface with VLAN 100.

**Customization:**

* `name: br-vlan100` - Bridge name
* `name: ens224` - Physical interface (update to your interface)
* `tag: 100` - VLAN tag

=== Linux Bridge NAD

xref:attachment$networking/linux-bridge-nad.yaml[Download linux-bridge-nad.yaml]

[source,yaml]
----
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: bridge-vlan100
  namespace: default
spec:
  config: |
    {
      "cniVersion": "0.3.1",
      "name": "bridge-vlan100",
      "type": "cnv-bridge",
      "bridge": "br-vlan100",
      "macspoofchk": true,
      "ipam": {}
    }
----

**Purpose:** NAD that references the Linux bridge for VM attachment.

**When to use:** When per-node isolation is acceptable and OVS is not available.

=== Related Tutorials

* xref:networking:linux-bridges.adoc[]

== Overlay Networks

OVN overlay networks provide cloud-like networking with automatic IPAM.

=== Overlay Network with DHCP

xref:attachment$networking/overlay-dhcp-nad.yaml[Download overlay-dhcp-nad.yaml]

[source,yaml]
----
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: overlay-dhcp
  namespace: default
spec:
  config: |
    {
      "cniVersion": "0.3.1",
      "name": "overlay-dhcp",
      "type": "ovn-k8s-cni-overlay",
      "topology": "layer2",
      "subnets": "10.200.0.0/16",
      "mtu": 1400,
      "netAttachDefName": "default/overlay-dhcp",
      "ipam": {
        "type": "ovn-k8s-cni-ipam",
        "provider": "ovn-kubernetes"
      }
    }
----

**Purpose:** Creates isolated overlay network with OVN-Kubernetes IPAM.

**When to use:** For cloud-like isolated networks without physical network dependencies.

**Benefits:**

* No physical network configuration required
* Automatic IPAM
* Network isolation
* Portable across nodes

== Bond Interfaces

Network bonding provides redundancy and increased bandwidth.

=== Bond Interface Configuration

xref:attachment$networking/bond-nncp.yaml[Download bond-nncp.yaml]

[source,yaml]
----
apiVersion: nmstate.io/v1
kind: NodeNetworkConfigurationPolicy
metadata:
  name: bond-config
spec:
  nodeSelector:
    node-role.kubernetes.io/worker: ""
  desiredState:
    interfaces:
      - name: bond0
        description: Active-backup bond
        type: bond
        state: up
        ipv4:
          enabled: false
        link-aggregation:
          mode: active-backup
          options:
            miimon: "100"
          port:
            - ens224
            - ens256
----

**Purpose:** Creates active-backup bond interface for redundancy.

**Bond Modes:**

* `active-backup` - One active, others standby
* `802.3ad` - LACP (requires switch support)
* `balance-rr` - Round-robin
* `balance-xor` - XOR hash-based

== Cluster Network Physical Mapping

For localnet topology, map logical network names to physical bridges:

[source,bash,role=execute]
----
# This is typically configured via NMState NNCP
# See operators manifest for OVS bridge mapping example
oc get nncp ovs-br-mapping -o yaml
----

The mapping defines:

* **Logical network name** (e.g., `physnet1`) - Used in NAD configurations
* **Physical bridge** (e.g., `br-ex`) - OVS bridge name on nodes

== Network Verification

=== Verify NADs

[source,bash,role=execute]
----
# List all NADs
oc get network-attachment-definition -A

# Describe specific NAD
oc describe network-attachment-definition <nad-name> -n <namespace>

# Check NAD in VM
oc get vmi <vm-name> -n <namespace> -o jsonpath='{.spec.networks[*]}'
----

=== Verify OVS Configuration

[source,bash,role=execute]
----
# Check OVS bridge mapping on node
oc debug node/<node-name>
chroot /host
ovs-vsctl show
ovs-vsctl get Open_vSwitch . external_ids:ovn-bridge-mappings
----

=== Test Network Connectivity

[source,bash,role=execute]
----
# Get VM IP
oc get vmi <vm-name> -n <namespace> -o jsonpath='{.status.interfaces[*].ipAddress}'

# Test from another VM or pod
ping <vm-ip>

# Inside VM console
virtctl console <vm-name> -n <namespace>
ip addr show
ip route show
----

== Common Network Patterns

=== Single Network (Pod Network Only)

[source,yaml]
----
spec:
  template:
    spec:
      networks:
        - name: default
          pod: {}
----

**Use case:** Simple VMs, development, testing.

=== Dual Network (Pod + Secondary)

[source,yaml]
----
spec:
  template:
    spec:
      networks:
        - name: default
          pod: {}
        - name: vlan-network
          multus:
            networkName: localnet-vlan-100
----

**Use case:** Production VMs with management (pod) and data (VLAN) networks.

=== Multiple Networks

[source,yaml]
----
spec:
  template:
    spec:
      networks:
        - name: default
          pod: {}
        - name: data-network
          multus:
            networkName: localnet-vlan-100
        - name: storage-network
          multus:
            networkName: localnet-vlan-200
----

**Use case:** Complex deployments with network segmentation.

== Troubleshooting

=== NAD Not Found

[source,bash]
----
Error: NAD "localnet-vlan-100" not found in namespace "default"
----

**Solution:** Create NAD in same namespace as VM or use `namespace/nad-name` format.

=== No Connectivity on Secondary Network

**Check:**

. NAD exists: `oc get nad -n <namespace>`
. OVS bridge configured: `oc get nncp`
. Physical switch configured for VLAN
. Cloud-init network configuration correct

=== VM Interface Not Getting IP

**Check:**

. IPAM configuration in NAD
. Cloud-init logs: `/var/log/cloud-init.log`
. Interface status: `ip addr show`
. DHCP client running: `nmcli device status`

== Summary

Key network manifest types:

* **Localnet NADs**: Direct physical network access
* **UDN**: Custom primary networks for VMs
* **Linux Bridge NADs**: Traditional bridge networking
* **Overlay NADs**: Cloud-like isolated networks
* **Bond configurations**: Network redundancy

== See Also

* xref:networking:index.adoc[]
* xref:manifests:operators.adoc[NMState Operator Configuration]
* xref:manifests:index.adoc[]

